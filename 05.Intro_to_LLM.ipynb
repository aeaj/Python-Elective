{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduktion i LLM i Python ###\n",
    "\n",
    "- Hvad er det grundlæggende ved en LLM og hvad kan det bruges til?\n",
    "\n",
    "- Hvad er RAG og Agentic RAG og hvorfor bruger man dem?\n",
    "\n",
    "- Hvad er Transformers, Embeddings og hvordan bruges de af LLMs?\n",
    "\n",
    "- Hvordan bruger man text, audio, image og video embeddings models?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hvad er RAG (Retrieval-augmented Generation)?**\n",
    "\n",
    "- Retrieve: Afhent\n",
    "- Augment: Forstørret\n",
    "- Generate: Generering\n",
    "\n",
    "RAG er en pipeline, hvor en AI-model kombinerer en LLM med eksterne informationskilder, som kan forbedre sin besvarelse fra en LLM.\n",
    "et fungerer ved at inkorporere relevante data fra en vektor database, tilføje dets kontekst til en prompt og overfører det til en LLM for generering.\n",
    "- En generativ model (LLM) generer tekst som svar på en PROMPT\n",
    "- RAG forbedrer denne proces ved at hente relevante data fra eksterne databaser, dokumenter eller API'er, får den genererer et svar\n",
    "\n",
    "Retrieval-Augmented: Retrieve relevant information to the users query, and generate the answer\n",
    "\n",
    "Generation: LLM, generates text from a user-query/prompt\n",
    "\n",
    "Three parts of the prompt:\n",
    "- Instruktion: \n",
    "\n",
    "Udfordringer ved normal LLM:\n",
    "- Ingen kilder\n",
    "- Forældet kilde\n",
    "\n",
    "Løsninger ved udfordringer:\n",
    "- LLM afhenter relevante data kun på trænet data, fordelen er mindre risiko for modellen hallucinerer eller lække data, og mere troværdige ved at svarer tilbage på hvad den ved og ikke ved. Ulempen kan være, at hvis \"retrieveren\" ikke er god nok, kan brugerens query ikke få et svar tilbage.\n",
    "- Opdatere datalager med nye opdaterede oplysninger\n",
    "\n",
    "Kilder:\n",
    "https://www.youtube.com/watch?v=T-D1OfcDW1M\n",
    "\n",
    "\n",
    "**Hvorfor bruges RAG?**\n",
    "\n",
    "- Traditionelle LLM'er uden RAG har forældet eller begrænset viden. Modellen er kun så god som den data, den blev trænet på\n",
    "- Tradionelle LLM'er risikerer at hallucineres, ved at opfinde falske ellr misvisende svar, hvis den mangler data. \n",
    "\n",
    "Fordel med RAG:\n",
    "- Henter opdaterede og troværdige data fra troværdige eksterne kilder eller database.\n",
    "- Svarene baseres på verificerede data og reducer risikoen for hallucinationer\n",
    "\n",
    "**Hvordan opdateres data i RAG?**\n",
    "\n",
    "- Ved at tilføje nye informationskilder\n",
    "- Forbedre søgealgoritmen, så den henter mere præcise resultater\n",
    "- Finetuning af modellen ved at give den flere eksempler på gode svar\n",
    "\n",
    "**Hvad er Transformers?**\n",
    "\n",
    "Arkitektur/Deep-learning model, som bruges i LLM til at forstå og generere tekst. Består af 2 hoveddele:\n",
    "- Encoder - Læser og forstår tekst\n",
    "- Decoder - Genererer ny tekst\n",
    "\n",
    "**Hvordan fungerer en LLM (Large Language Models)?**\n",
    "\n",
    "Maskinlæringsmode baseret på netural netværkteknikker, til at forstå og generere sprog trænet på massive tekstdata.\n",
    "\n",
    "Fungerer ved hjælp af deep learning, som er trænet på massive datasæt og masse tekniske egenskaber \n",
    "\n",
    "**Hvad er Embeddings og hvordan bruges de i LLM?**\n",
    "\n",
    "Embeddings er kontinuerlig vektor repræsentationer af diskrete data. De fungerer som en bro mellem de rå data og maskinlæringsmodellerne ved at konvertere kategoriske eller tekstdata til numerisk form, som modeller kan behandle effektivt. Målet med indlejringer er at fange den semantiske betydning og relationer inden for dataene på en måde, at lignende genstande er tættere sammen i indlejringsrummet.\n",
    "\n",
    "Embeddinger er afgørende, fordi de gør det muligt for modeller at håndtere og lære af højdimensionelle data effektivt. De reducerer beregningsmæssig kompleksitet og øger evnen til at generalisere fra dataene\n",
    "\n",
    "**Hvordan bruger man text, audio, image, video embedding models?**\n",
    "\n",
    "Tekst:\n",
    "Word indlejringer bruges til at repræsentere ord i et kontinuerligt vektorrum. Populære teknikker omfatter Word2Vec, GloVe og FastText. Disse metoder lærer indlejringer baseret på den kontekst, hvori ord vises, idet de fanger semantiske ligheder mellem ord.\n",
    "Eksempel\n",
    "\n",
    "I Word2Vec kan ordene \"konge\" og \"dronning\" have lignende vektorer, fordi de deler lignende sammenhænge, mens \"konge\" og \"æble\" ville have forskellige vektorer på grund af deres forskellige sammenhænge.\n",
    "\n",
    "Audio:\n",
    "Lydindlejringer konverterer lydsignaler til et lavere dimensionelt rum, der fanger væsentlige funktioner som fonetisk indhold, højttaleregenskaber eller følelsesmæssig tone. Disse indlejringer er almindeligt anvendt i opgaver som talegenkendelse, højttaleridentifikation og følelsesdetektering.\n",
    "Eksempel\n",
    "\n",
    "Mel-frekvens cepstral koefficienter (MFCC'er) er almindeligt anvendte funktioner til lydindlejringer. Mere avancerede teknikker involverer brug af præ-trænede modeller som VGGish, som er baseret på VGG-arkitekturen, men tilpasset til lyddata.\n",
    "\n",
    "Image:\n",
    "I computersyn genereres billedindlejringer for at repræsentere billeder i et lavere dimensionelt rum. Convolutional Neural Networks (CNN'er) udtrækker ofte disse indlejringer fra de sidste lag af netværket, som derefter kan bruges til opgaver som billedklassifikation, objektdetektering og billedlighed.\n",
    "Eksempel\n",
    "\n",
    "Et CNN kan producere en 256-dimensionel indlejring til et billede af en kat, som derefter kan sammenlignes med andre indlejringer for at finde lignende billeder eller klassificere billedet som en kat.\n",
    "\n",
    "\n",
    "Video: ???\n",
    "\n",
    "**Hvordan bruges Mistral.ai embeddings i API'er i sammenspil med ChromaDB?**\n",
    "\n",
    "- Mistral.ai tilbyder en API der kan generere embeddings fra tekst.\n",
    "- ChromaDB er en vektordatabase til at gemme og forespørge embeddings\n",
    "- Gem embedings MAI i databasen\n",
    "- Databasen giver dig mulighed for hurtigt at finde embeddings der er tæt på en forespørgselsembedding\n",
    "\n",
    "I en typisk API-integration vil du:\n",
    "\n",
    "- Modtage en tekstforespørgsel fra en bruger.\n",
    "- Bruge Mistral AI's embeddings-API til at generere en embedding for forespørgslen.\n",
    "- Bruge ChromaDB til at søge efter embeddings, der er tæt  forespørgselsembeddingen.\n",
    "- Hente de tilsvarende tekster fra din database.\n",
    "- Returnere resultaterne til brugeren.\n",
    "\n",
    "**Kilder**\n",
    "https://www.geeksforgeeks.org/what-is-retrieval-augmented-generation-rag/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hvad er AI-Agents?**\n",
    "\n",
    "Systemer, der kan forstå, planlægge og handle ved at kombinere forskellige komponenter såsom store sprogmodeller (LLMs), værktøjer og hukommelse.\n",
    "\n",
    "Shift models: Isoleret AI-modeller \n",
    "- Tradionel LLM der kun svarer ud fra sin træning\n",
    "- Begrænset viden, til den data de er trænet på\n",
    "- Svært tilpasning, kræver mængder af data og ressourcer\n",
    "- Kræver Finetunning\n",
    "- Eksempel: En statisk chatbot, der kun kan svare baseret på dens forudtrænede viden, men kan ikke søge på internettet.\n",
    "\n",
    "Compound AI-System: Sytem design principper\n",
    "- Kombinerer flere komponenter og flere værktøjer\n",
    "- LLM kan søge efter eksterne værktøjer, som databaser, søgning i web, brug af API'er, osv...\n",
    "- Dynamisk læring, hvilket kan hente opdaterede data i realtid. Ergo, nemmere at tilpasse sig.\n",
    "- Eksempel:En AI-agent(Le Chat), der kombinerer en LLM med en internetsøgemaskine, så den kan finde de nyeste informationer.\n",
    "\n",
    "Kontrol logik:\n",
    "1. Pragmatisk kontrol\n",
    "- Fordel: Hurtig generering, \n",
    "- God til små og veldefinerede problemer\n",
    "- De fleste compound systems har en pragmatisk kontrol logik.\n",
    "\n",
    "2. Agent-baseret kontrol (Generisk):\n",
    "- Dybere ræsonnering, bedre til komplekse opgaver\n",
    "- Bryder problemerne ned\n",
    "- Langsommere generering\n",
    "\n",
    "Komponenter i LLM Agent:\n",
    "1. Planlægning (Reasoning): Modellen analyserer problemet/prompt/query og laver en trin-for-trin plan for at løse det.\n",
    "\n",
    "2. Handling (Take Action): Modeller bruger værktøjer til at hente ellr genrere information. Eksempler på værktøjer: \n",
    "- Websøgning , \n",
    "- Database-forespørgsel, \n",
    "- Lommeregner, \n",
    "- API-kald\n",
    "- Sprogmodeller\n",
    "- API\n",
    "- Med mere\n",
    "\n",
    "3. Hukommelse: Modellen kan gemme logfiler fra tidligere prompts, for senere brug.\n",
    "- Eksempel: Gemme tidligere samtaler for at gøre interaktionen mere personlig\n",
    "\n",
    "**Hvad er AI_autonomi?**\n",
    "\n",
    "- Hvor meget frihed agenten har til at tage beslutninger uden menneskelig input. \n",
    "\n",
    "**Hvad sker der, når en ReAct-agent konfigureres?**\n",
    "\n",
    "1. User Query: Brugeren stiller en forespørgsel/prompt, som bliver overført til modellen/LLM.\n",
    "2. Plan slow: LLM planlægger tager sig god tid til at tænke på et relevant svar der matcher user query.\n",
    "3. Act: Modellen forsøger at handle (f.eks. via eksterne værktøjer) \n",
    "4. Observe: Modellen evaluerer svaret:\n",
    "- Hvis svarer besvarer brugerens prompt: Returner det til brugeren\n",
    "- Ellers: Gentages/Itereres processen indtil prompten endelig er besvaret\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hvad er Agentic RAG?**\n",
    "\n",
    "Agentic RAG (Retrieval-Augmented Generation) er en avanceret version af den klassiske RAG-arkitektur, der kombinerer information hentet fra eksterne kilder med en Large Language Model (LLM) for at generere mere præcise og kontekstuelle svar. Agentic betyder, at modellen fungerer som en \"agent\", der kan tage flere beslutninger, planlægge og iterativt forbedre sin informationssøgning.\n",
    "\n",
    "Uden RAG:\n",
    "1. Bruger/Applikation sender en query: \"Hvordan opretter jeg en vare?\"\n",
    "2. Query bliver omsat til en prompt\n",
    "3. Overføres til en LLM\n",
    "4. Som genererer en output.\n",
    "\n",
    "Udfordringer:\n",
    "- Fordel: Hurtig Setup. Kræver API-nøgle og Prompt eng.\n",
    "- Ulempe: Svar et upræcis og hallucinerende. Trækker kun generel indhold, ikke fra en specifik dokumentation\n",
    "- F.eks. Kan modellen give generelle råd på baggrund af typiske POS systemer, som risikerer ikke at ramme præcist vores POS system.\n",
    "\n",
    "Med RAG:\n",
    "1. User query: Bruger/Applikation sender en query\n",
    "2. Txt Embeddings: Query omdannes til en vektor via en embedding funktion\n",
    "3. Retrieval: Vektoren bruges til at søge i en vektordatabase (fx ChromaDB), som indeholder embeddings af alle teksudnit\n",
    "Databasen returnerer de x mest relevante tekstudnist, som dækker præcis, hvor i dokumentet besvarelsen til spørgsmålet bliver forklaret.\n",
    "4. Prompt Construct: De hentede tekstudsnit (“dokumentkontekst”) sættes foran eller indlejres i prompten,\n",
    "5. Generering: LLM’en (f.eks. GPT-3.5 eller Mistral) bruger både prompten (brugerspørgsmål) og det specifikke kontekst-udsnit for at danne et nøjagtigt svar.\n",
    "Output: Svaret returneres til klienten som JSON via /chat.\n",
    "\n",
    "Udfordringer:\n",
    "- Fordel: Præcision. Henter fra eget dokumentation og hvis dokumentet opdateres, re-indektserer man blot ChromaDB/vektordatabasen, og så er ny viden klar.\n",
    "- Ulempe: Kræver ekstra og mere opsætning (Embeddings, vektor database, osv...) og højere latency, da retrieval-trinnet skal køres først. \n",
    "\n",
    "Agentic RAG:\n",
    "- Bygger videre på den almindelige RAG-arkitektur, men med et ekstra lag (Agent), som selv vurderer hvilke værktøjer/databaser der skal retrieves/afhentes/bruges, på baggrund af user query\n",
    "\n",
    "Udfordringer:\n",
    "- Fordel: Fleksibilitet og multi-trins-logik. API kald kan automatiseres og kan håndtere komplekse scenarier der kræver flere værktøjer på en gang.\n",
    "- Ulempe: Kræver meget mere ekstra opsætning, samt krævder det en forme for agent-framework, f.eks. hos Langchain. \n",
    "\n",
    "https://www.youtube.com/watch?v=F8NKVhkZZWI\n",
    "https://www.geeksforgeeks.org/what-is-agentic-rag/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings ##\n",
    "\n",
    "**Hvad er Embeddings og hvordan bruges de i LLM?**\n",
    "\n",
    "Embeddings er data (Som ord), der er blevet konverteret til numeriske arrays kendt som en vektor, der indeholder mønstre af forhold/forbindelser\n",
    "\n",
    "Embeddings er kontinuerlig vektor repræsentationer af diskrete data. De fungerer som en bro mellem de rå data og maskinlæringsmodellerne ved at konvertere kategoriske eller tekstdata til numerisk form, som modeller kan behandle effektivt. Målet med indlejringer er at fange den semantiske betydning og relationer inden for dataene på en måde, at lignende genstande er tættere sammen i indlejringsrummet.\n",
    "\n",
    "Embeddinger er afgørende, fordi de gør det muligt for modeller at håndtere og lære af højdimensionelle data effektivt. De reducerer beregningsmæssig kompleksitet og øger evnen til at generalisere fra dataene\n",
    "\n",
    "**Hvordan bruger man text, audio, image, video embedding models?**\n",
    "\n",
    "Tekst:\n",
    "Word indlejringer bruges til at repræsentere ord i et kontinuerligt vektorrum. Populære teknikker omfatter Word2Vec, GloVe og FastText. Disse metoder lærer indlejringer baseret på den kontekst, hvori ord vises, idet de fanger semantiske ligheder mellem ord.\n",
    "Eksempel\n",
    "\n",
    "I Word2Vec kan ordene \"konge\" og \"dronning\" have lignende vektorer, fordi de deler lignende sammenhænge, mens \"konge\" og \"æble\" ville have forskellige vektorer på grund af deres forskellige sammenhænge.\n",
    "\n",
    "Audio:\n",
    "Lydindlejringer konverterer lydsignaler til et lavere dimensionelt rum, der fanger væsentlige funktioner som fonetisk indhold, højttaleregenskaber eller følelsesmæssig tone. Disse indlejringer er almindeligt anvendt i opgaver som talegenkendelse, højttaleridentifikation og følelsesdetektering.\n",
    "Eksempel\n",
    "\n",
    "Mel-frekvens cepstral koefficienter (MFCC'er) er almindeligt anvendte funktioner til lydindlejringer. Mere avancerede teknikker involverer brug af præ-trænede modeller som VGGish, som er baseret på VGG-arkitekturen, men tilpasset til lyddata.\n",
    "\n",
    "Image:\n",
    "I computersyn genereres billedindlejringer for at repræsentere billeder i et lavere dimensionelt rum. Convolutional Neural Networks (CNN'er) udtrækker ofte disse indlejringer fra de sidste lag af netværket, som derefter kan bruges til opgaver som billedklassifikation, objektdetektering og billedlighed.\n",
    "Eksempel\n",
    "\n",
    "Et CNN kan producere en 256-dimensionel indlejring til et billede af en kat, som derefter kan sammenlignes med andre indlejringer for at finde lignende billeder eller klassificere billedet som en kat.\n",
    "\n",
    "\n",
    "Video: ???\n",
    "\n",
    "**Hvordan bruges Mistral.ai embeddings i API'er i sammenspil med ChromaDB?**\n",
    "\n",
    "- Mistral.ai tilbyder en API der kan generere embeddings fra tekst.\n",
    "- ChromaDB er en vektordatabase til at gemme og forespørge embeddings\n",
    "- Gem embedings MAI i databasen\n",
    "- Databasen giver dig mulighed for hurtigt at finde embeddings der er tæt på en forespørgselsembedding\n",
    "\n",
    "I en typisk API-integration vil du:\n",
    "\n",
    "- Modtage en tekstforespørgsel fra en bruger.\n",
    "- Bruge Mistral AI's embeddings-API til at generere en embedding for forespørgslen.\n",
    "- Bruge ChromaDB til at søge efter embeddings, der er tæt  forespørgselsembeddingen.\n",
    "- Hente de tilsvarende tekster fra din database.\n",
    "- Returnere resultaterne til brugeren.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Øvelse - Text Embeddings ##"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

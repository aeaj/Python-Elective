{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langchain og Retrieal-Augmented Generation ###\n",
    "\n",
    "- Hvad er Langchain og hvordan kan det bruges i at udfører opgaver?\n",
    "\n",
    "- Hvad er konceptet i RAG?\n",
    "\n",
    "- Hvad er en RAG Pipeline og hvorfor bruger man det?\n",
    "\n",
    "- Hvad er koncepterne Indexing, Retrieval, Generation i en RAG sammenhæng?\n",
    "\n",
    "- Hvordan laver man basale RAG applikationer med brug af Langchain og en LLM?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hvad er Langchain?\n",
    "\n",
    "Open source Framework der gør det lettere at udvikle AI-applikationer med LLM.\n",
    "\n",
    "Består af:\n",
    "- LLM (Kan integrere forskellige LLM'er, Mistral, OpenAI, osv...)\n",
    "- Prompts\n",
    "- Chains \n",
    "- Indeks (Document loader, Vector Databases, Text Splitters)\n",
    "- Memory (Huske tidligere samtalehistorik)\n",
    "- Agents \n",
    "\n",
    "Hvad kan Langchain bruges til?\n",
    "- Chatbot\n",
    "- Summarization\n",
    "- Question answering\n",
    "- Data augmentation\n",
    "- Virtuelle agents (RPA)\n",
    "\n",
    "Langchains værktøjer og API'er forenkler processen i udvikling af applikationer der gør brug af LLM.\n",
    "\n",
    "## Hvad er koncepterne indexing, retrieval og generation i en RAG sammenhæng?\n",
    "\n",
    "RAG-sammenhæng\n",
    "\n",
    "Overordnet proces:\n",
    "- Henter docs\n",
    "- Split docs for embedding eller convenience\n",
    "- Embed hvert split\n",
    "- Gemmer det i et vektorlager (numeriske repræsentationer af docs splits, samt relevant spørgsmål i et dictionary{} som videreføres til en\n",
    "- prompt template -> promptvalue -> LLM -> chatmessage to Parser -> String svar)\n",
    "\n",
    "Question -> Indeks(Docs) -> Retrieval(Relevant Docs) -> Generation() -> Answer\n",
    "\n",
    "## Hvordan laver man basic RAG applikation med brug af Langchain og en LLM?\n",
    "\n",
    "\n",
    "PART 1 - Grundlæggende\n",
    "Kodestruktur:\n",
    "\n",
    "- Install a few packages\n",
    "- Set up environment variables\n",
    "\n",
    "Indeks\n",
    "- Load documents\n",
    "- Split the docs\n",
    "- Hvert split er indlejret  og indekseret i en vektor-store (F.eks. Chroma lokalt)\n",
    "\n",
    "Retrieval And generation\n",
    "- Prompt\n",
    "- LLM\n",
    "- Chain (Prompt, LLm, String)\n",
    "- Question\n",
    "\n",
    "Part 2 - Indeks\n",
    "\n",
    "Lagring og struktur af dataen, så den kan findes hurtigere\n",
    "- Numerical representation of text documents\n",
    "- Define number of tokens(Docs size)\n",
    "- Specificere embeddings\n",
    "- Vektor repræsentation af embeddings...\n",
    "\n",
    "PART 3 - Retrieval\n",
    "\n",
    "Søgning efter mest relevant information i dataen\n",
    "- Docs -> Embed both query and docs -> Vektorstore ->\n",
    "- Integrations\n",
    "- Define k in retriever\n",
    "\n",
    "PART 4 - Generation\n",
    "\n",
    "LLM'en bruger den fundne information til at lave præcisere svaret, så det er relevant til query'en.\n",
    "- Define Prompt template\n",
    "- Define LLM (F.eks. GPT)\n",
    "- Define chain \n",
    "- Kør chain template\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
